{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "induced-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.stats import randint\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "angry-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "artificial-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern, greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worth-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif,chi2\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classical-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Read Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-identifier",
   "metadata": {},
   "source": [
    "classes_dir = ['ayak_parmaklari_enfekte_ve_nerkotik', \"basinc_ulseri_1\",'basinc_ulseri_2','cesitli_yaralar','diyabetik_ayak_ulserleri'\n",
    "               ,'ektravazaston_yarasi','epidermolizis_bulloza',\"karin_yarasi\",\"hemanjiyomlar\",\"kotu_huylu_yaralar\",\n",
    "               \"menenjit_yaralari\",\"ortopedik_yaralar\",\"pilanidal_sinus_yaralari\",\"venos_ulserler_arteriyel_ulserler_Set_1\",\n",
    "               \"venoz_ve_artiyel_ulser_set_2\", \"yanik_yarasi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demanding-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dir = ['ayak_parmaklari_enfekte_ve_nerkotik', 'basinc_ulseri_1','cesitli_yaralar','diyabetik_ayak_ulserleri'\n",
    "               ,'ektravazaston_yarasi',\"hemanjiyomlar\",\"karin_yarasi\",\"kotu_huylu_yaralar\",\"menenjit_yaralari\",\n",
    "               \"ortopedik_yaralar\",\"venos_ulserler_arteriyel_ulserler_Set_1\", \"yanik_yarasi\"]\n",
    "\n",
    "dim = (64, 64)\n",
    "datanpy_path = \"DataNpy\"\n",
    "\n",
    "def get_data(data_dir):\n",
    "    data = []\n",
    "    sinif = []\n",
    "    for sınıf in classes_dir:\n",
    "        path = os.path.join(data_dir, sınıf)\n",
    "        class_num = classes_dir.index(sınıf)\n",
    "        for img in os.listdir(path):\n",
    "            img_arr = cv2.imread(os.path.join(path, img))#convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, dim) # Reshaping images to preferred size\n",
    "            sinif.append(class_num)\n",
    "            data.append(resized_arr)\n",
    "    \n",
    "    np.save(os.path.join(datanpy_path,'raw_data'),np.array(data)), np.save(os.path.join(datanpy_path,'classes'),np.array(sinif))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "difficult-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features to numpyData: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eight-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"Features\"\n",
    "\n",
    "def to_numpyData(features, name, save=False):\n",
    "    np.save(os.path.join(feature_path, name + '_features'), np.array(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "valuable-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hog Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "constant-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(images, val=False, test=False):\n",
    "    # HOG Feature Extraction\n",
    "    cell_size = (4, 4)    \n",
    "    block_size = (2, 2)     \n",
    "    nbins = 9\n",
    "    \n",
    "    hog_desc = cv2.HOGDescriptor(_winSize=(images[0].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                              images[0].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                    _blockSize=(block_size[1] * cell_size[1],\n",
    "                                                block_size[0] * cell_size[0]),\n",
    "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                    _nbins=nbins)\n",
    "    \n",
    "    def get_image_hog(image):\n",
    "        # HOG feature\n",
    "        f = hog_desc.compute(image)\n",
    "        \n",
    "        res = np.array(f)\n",
    "        return res.flatten()\n",
    "    \n",
    "    # HOG for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        f = get_image_hog(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "        features.append(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(features, 'hog')\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(features, 'hog_val')\n",
    "        \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(features, \"hog_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sophisticated-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gabor based Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dimensional-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gabor(images, val=False, test=False):\n",
    "    filters = []\n",
    "    ksize = 9\n",
    "    sigma = 0.1\n",
    "    gamma = 0.5\n",
    "    phi = 0\n",
    "    \n",
    "    # define the range for theta and nu\n",
    "    for theta in np.arange(0, np.pi, np.pi / 8):\n",
    "        for nu in np.arange(0, 6*np.pi/4, np.pi / 4):\n",
    "            kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, nu, gamma, phi, ktype=cv2.CV_32F)\n",
    "            kern /= 1.5*kern.sum()\n",
    "            filters.append(kern)\n",
    "    \n",
    "    # function to convolve the image with the filters\n",
    "    def process(img, filters):\n",
    "        accum = np.zeros_like(img)\n",
    "        for kern in filters:\n",
    "            fimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n",
    "            np.maximum(accum, fimg, accum)\n",
    "            return accum\n",
    "        \n",
    "    \n",
    "    def get_image_gabor(image):\n",
    "        # Local Binary Pattern\n",
    "        f = []\n",
    "\n",
    "        # calculating the local energy for each convolved image\n",
    "        for j in range(40):\n",
    "            res = process(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), filters[j])\n",
    "            res = np.array(res)\n",
    "            f.append(np.sum(np.multiply(res, res)))\n",
    "\n",
    "        # calculating the mean amplitude for each convolved image\n",
    "        for j in range(40):\n",
    "            res = process(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), filters[j])\n",
    "            res = np.array(res)\n",
    "            f.append(np.sum(abs(res)))\n",
    "        return f\n",
    "    \n",
    "    # Gabor descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        f = get_image_gabor(img)\n",
    "        features.append(f)\n",
    "    \n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(features, \"gabor\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(features, \"gabor_val\")\n",
    "        \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(features, \"gabor_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "retained-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KAZE based features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contrary-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaze(images, val=False, test=False):\n",
    "    \n",
    "    # KAZE descriptor for 1 image\n",
    "    def get_image_kaze(image, vector_size=32):\n",
    "        algo = cv2.KAZE_create()\n",
    "        kps = algo.detect(image)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = algo.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        \n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "        return dsc\n",
    "    \n",
    "    # KAZE descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_kaze(img)\n",
    "        features.append(dsc)    \n",
    "        \n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(features, \"kaze\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(features, \"kaze_val\")\n",
    "        \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(features, \"kaze_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "invalid-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale-invariant feature transform (SIFT) based Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c491a302-2f8c-49eb-803e-d31973169d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift(images, val=False, test=False):\n",
    "    \n",
    "    # SIFT descriptor for 1 image\n",
    "    def get_image_sift(image, vector_size=15):\n",
    "        alg = cv2.xfeatures2d.SIFT_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 128\n",
    "        needed_size = (vector_size * 128)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SIFT descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_sift(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(features, \"sift\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(features, \"sift_val\")\n",
    "    \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(features, \"sift_test\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4258b-4168-4e0c-842d-f85dbf49ac63",
   "metadata": {},
   "source": [
    "## Speeded-up robust features (SURF) based Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5ce6c-a8ce-4e9c-9296-5a38d579a604",
   "metadata": {},
   "source": [
    "\n",
    "def get_surf(images):\n",
    "    # SURF descriptor for 1 image\n",
    "    def get_image_surf(image, vector_size=4):\n",
    "        alg = cv2.xfeatures2d.SURF_create()\n",
    "        #alg = cv2.xfeatures2d_SURF.create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SURF descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_surf(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    result = np.array(features)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "convertible-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local-Binary-Pattern (LBP) based Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "discrete-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp(images, val=False, test=False):\n",
    "    result = np.array([local_binary_pattern(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 10, 3).flatten() for img in images])\n",
    "    \n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(result, \"LBP\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(result, \"LBP_val\")\n",
    "    \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(result, \"LBP_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accompanied-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gray Level Co-occurrence Matrix (GLCM) based Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hundred-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glcm(images, val=False, test=False):\n",
    "    \n",
    "    # GLCM feature for 1 image\n",
    "    def get_image_glcm(img):\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # GLCM Feature Extraction\n",
    "        Grauwertmatrix = greycomatrix(image, [1, 2, 3], [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4],\n",
    "                                                  symmetric=False, normed=True)\n",
    "        \n",
    "        contrast = greycoprops(Grauwertmatrix, 'contrast')\n",
    "        dissimilarity = greycoprops(Grauwertmatrix, 'dissimilarity')\n",
    "        homogeneity = greycoprops(Grauwertmatrix, 'homogeneity')\n",
    "        energy = greycoprops(Grauwertmatrix, 'energy')\n",
    "        correlation = greycoprops(Grauwertmatrix, 'correlation')\n",
    "        ASM = greycoprops(Grauwertmatrix, 'ASM')\n",
    "        \n",
    "        # Merge all the features\n",
    "        f = np.array([contrast, dissimilarity, homogeneity, energy, correlation, ASM])\n",
    "        return f.flatten()\n",
    "    \n",
    "    \n",
    "    # GLCM descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_glcm(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(features,\"glcm\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(features, \"glcm_val\")\n",
    "    \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(features, \"glcm_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "transsexual-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattened Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sunrise-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened(images, val=False, gray=False, test=False, color=cv2.COLOR_BGR2RGB): \n",
    "    \n",
    "    color_images = []\n",
    "    if color is not None:\n",
    "        for img in images:\n",
    "            color_images.append(cv2.cvtColor(img, color))\n",
    "    else:\n",
    "        color_images = images\n",
    "    \n",
    "    count = len(color_images)\n",
    "    \n",
    "    result = np.array(color_images).reshape(count, -1)\n",
    "        \n",
    "    if gray == True and test==True:\n",
    "        to_numpyData(result, \"gray_test\")\n",
    "        \n",
    "    elif gray == False and test==True:\n",
    "        to_numpyData(result, \"rgb_test\")\n",
    "        \n",
    "    elif val == False and gray == False:\n",
    "        to_numpyData(result, \"rgb\")\n",
    "        \n",
    "    elif val == True and gray == False:\n",
    "        to_numpyData(result, \"rgb_val\")\n",
    "        \n",
    "    elif val == False and gray == True:\n",
    "        to_numpyData(result, \"gray\")\n",
    "        \n",
    "    elif val == True and gray == True:\n",
    "        to_numpyData(result, \"gray_val\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "manual-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color Histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ongoing-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hist(images, val=False, test=False):\n",
    "    histograms = []\n",
    "    for img in images:\n",
    "        histograms.append(cv2.calcHist([img], [0, 1, 2],None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten())\n",
    "    \n",
    "    if val == False:\n",
    "        to_numpyData(histograms, \"color_histogram\")\n",
    "        \n",
    "    if val == True:\n",
    "        to_numpyData(histograms, \"color_histogram_val\")\n",
    "    \n",
    "    if test == True and val == False:\n",
    "        to_numpyData(histograms, \"color_histogram_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "formal-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becoming-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_minmax(train):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    \n",
    "    \n",
    "    return norm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "therapeutic-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features_zscore(train, test):\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "enclosed-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fossil-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data('yaralar3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adjacent-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_x = np.load(os.path.join(datanpy_path, 'raw_data.npy'))\n",
    "full_data_y = np.load(os.path.join(datanpy_path, 'classes.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "armed-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, test_x, data_y, test_y = train_test_split(full_data_x, full_data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "christian-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs, train_y, val_y = train_test_split(data_x, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "virtual-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HOG Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latter-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hog(train_imgs)\n",
    "get_hog(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "violent-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LBP Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "early-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lbp(train_imgs)\n",
    "get_lbp(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "inner-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KAZE Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eight-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kaze(train_imgs)\n",
    "get_kaze(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "herbal-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIFT Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "approved-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sift(train_imgs)\n",
    "get_sift(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fatty-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gabor Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "split-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gabor(train_imgs)\n",
    "get_gabor(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baking-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLCM Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "popular-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_glcm(train_imgs)\n",
    "get_glcm(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bulgarian-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RGB Flatten Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "seven-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_flattened(train_imgs, val=False, gray=False)\n",
    "get_flattened(val_imgs, val=True, gray=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "descending-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gray Flatten Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mathematical-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_flattened(train_imgs, val=False, gray=True, color=cv2.COLOR_RGB2GRAY)\n",
    "get_flattened(train_imgs, True, gray=True, color=cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "active-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color Histogram Train and Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "casual-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_color_hist(train_imgs)\n",
    "get_color_hist(val_imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "interim-retailer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-7d97e98f8af7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0masdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unknown-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_test = get_hog(test_x, False, True)\n",
    "lbp_test = get_lbp(test_x, False, True)\n",
    "kaze_test = get_kaze(test_x, False, True)\n",
    "sift_test = get_sift(test_x, False, True)\n",
    "#surf_test = get_surf(test_x)\n",
    "gabor_test = get_gabor(test_x, False, True)\n",
    "glcm_test = get_glcm(test_x, False, True)\n",
    "flat_rgb_test = get_flattened(test_x, gray=False, test=True)\n",
    "flat_gray_test = get_flattened(test_x, gray=True, test=True, color=cv2.COLOR_RGB2GRAY)\n",
    "hist_test = get_color_hist(test_x, False, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
